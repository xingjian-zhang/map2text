"""
Generate ideas with non-trainable generator models.

Supported generator models:
- `zero-shot-prompting`
- `cot-prompting`
- `interpolate-embedding`
- `weighted-interpolate-embedding`
- `plagiarism`
"""

import json
import os
from typing import Any, Dict, List, Tuple

import numpy as np
import torch
import tqdm
import vec2text

from llm4explore.model.base import IdeaGenerator
from llm4explore.model.common import ANNSampler, KNNSampler, QRTask
from llm4explore.utils.api import process_chat_requests


def references_to_dict(
    data_old: List[str],
    indices: List[int],
    dists: List[float],
) -> List[Dict[str, str]]:
    """Format references as a list of dictionaries for logging."""
    return [
        {
            "reference": data_old[i],
            "distance": round(d, 4),
        }
        for i, d in zip(indices, dists)
    ]


class PlagiarismGenerator(IdeaGenerator):
    """Plagiarism-based idea generator.

    This generator uses a nearest neighbor search to find the most similar idea
    in the training data and returns it as the generated idea.
    """

    def __init__(
        self,
        n_dims: int,
        data_old: List[str],
        low_dim_embeddings_old: np.ndarray,
        sampler_kwargs: Dict[str, Any] = None,
    ):
        super().__init__(n_dims, data_old, low_dim_embeddings_old)
        sampler_kwargs = sampler_kwargs or {}
        self.sampler = ANNSampler(low_dim_embeddings_old, **sampler_kwargs)

    def decode(self, low_dim_embedding: np.ndarray) -> Tuple[str, Any]:
        indices, dists = self.sampler.sample(low_dim_embedding)
        return self.texts[indices[0]], references_to_dict(self.texts, indices, dists)


class EmbeddingBasedGenerator(IdeaGenerator):
    """Embedding-based idea generator.

    This generator uses a (weighted) interpolation of the high-dimensional embeddings
    of the training data to generate new ideas.

    Note: This generator requires the high-dimensional embeddings to be
    generated by text-embedding-ada-002 as it depends on vec2text for decoding.
    """

    def __init__(
        self,
        n_dims: int,
        data_old: List[str],
        low_dim_embeddings_old: np.ndarray,
        high_dim_embeddings_old: np.ndarray,
        weighted: bool = False,
        sampler_kwargs: Dict[str, Any] = None,
        vec2text_kwargs: Dict[str, Any] = None,
    ):
        assert high_dim_embeddings_old.shape[1] == 1536, (
            "High-dimensional embeddings must have 1536 dimensions. "
            "Please use text-embedding-ada-002 to generate the embeddings."
        )
        super().__init__(n_dims, data_old, low_dim_embeddings_old)
        sampler_kwargs = sampler_kwargs or {}
        vec2text_kwargs = vec2text_kwargs or {}
        self.weighted = weighted
        self.high_dim_embeddings_old = high_dim_embeddings_old
        self.sampler = ANNSampler(low_dim_embeddings_old, **sampler_kwargs)
        self.vec2text_kwargs = vec2text_kwargs
        self.vec2text_corrector = vec2text.load_corrector("text-embedding-ada-002")

    def decode(self, low_dim_embedding: np.ndarray) -> Tuple[str, Any]:
        # Sample nearest neighbors and interpolate high-dimensional embeddings.
        indices, dists = self.sampler.sample(low_dim_embedding)
        high_dim_embeddings = self.high_dim_embeddings_old[indices]
        dists = np.array(dists)
        weights = 1 / (dists + 1e-6) if self.weighted else np.ones_like(dists)
        high_dim_embedding = np.average(high_dim_embeddings, axis=0, weights=weights)
        # Generate text from the interpolated high-dimensional embedding using vec2text.
        if high_dim_embedding.ndim == 1:
            high_dim_embedding = high_dim_embedding[None, :]
        return vec2text.invert_embeddings(
            torch.tensor(
                high_dim_embedding,
                dtype=self.vec2text_corrector.model.dtype,
                device=self.vec2text_corrector.model.device,
            ),
            self.vec2text_corrector,
            **self.vec2text_kwargs,
        )[0], references_to_dict(self.texts, indices, dists)


class PromptingBasedGenerator(IdeaGenerator):
    """Prompting-based idea generator.

    This generator uses a prompting-based model to generate new ideas based
    on semantically similar ideas in the training data.
    """

    def __init__(
        self,
        model_name: str,
        prompt_type: str,
        target: str,
        n_dims: int,
        texts: List[str],
        low_dim_embeddings: np.ndarray,
        times: np.ndarray,
        rag_kwargs: Dict[str, Any] = None,
        sampler_kwargs: Dict[str, Any] = None,
        api_kwargs: Dict[str, Any] = None,
    ):
        super().__init__(n_dims, texts, low_dim_embeddings)
        self.times = times
        self.model_name = model_name
        self.prompt_type = prompt_type
        self.target = target
        sampler_kwargs = sampler_kwargs or {}
        rag_kwargs = rag_kwargs or {}
        api_kwargs = api_kwargs or {}
        self.sampler = KNNSampler(low_dim_embeddings, times, **sampler_kwargs)
        self.rag_kwargs = rag_kwargs
        self.api_kwargs = api_kwargs
        self.test_time = np.max(times) + 1
        prompt_path = os.path.join(
            os.path.dirname(__file__), "prompts", prompt_type + ".json"
        )
        with open(prompt_path, "r") as f:
            self.prompt_messages = json.load(f)

    def get_prompt(self, task: QRTask) -> List[Dict[str, str]]:
        """Get the prompting messages for the given task."""
        messages = []
        # System message and (optional) few shot examples.
        messages.extend(self.prompt_messages)
        # If RAG is enabled, add retrieved examples.
        if "rag" in self.prompt_type:
            retrieved_tasks = self.retrieve_relevant_tasks(task)
            for retrieved_task in retrieved_tasks:
                messages.extend(
                    self.task_to_messages(retrieved_task, include_answer=True)
                )
        # User message for the task.
        messages.extend(self.task_to_messages(task, include_answer=False))
        return messages

    def task_to_messages(
        self, task: QRTask, include_answer: bool = False
    ) -> List[Dict[str, str]]:
        """Convert a QRTask to a list of prompting messages. If include_answer
        is True, a user message and an assistant message are returned.
        Otherwise, only the user message is returned.
        """
        joined_ref_texts = "\n".join(task.references_texts)
        user_message = {
            "role": "user",
            "content": f"Predict new {self.target} based on these {self.target}s: {joined_ref_texts}",
        }
        if include_answer:
            assistant_message = {
                "role": "assistant",
                "content": f'{{"predictions": [{{"{self.target}": "{task.query_text}"}}]}}',
            }
            return [user_message, assistant_message]
        return [user_message]

    def retrieve_relevant_tasks(self, query_task: QRTask) -> List[QRTask]:
        """Retrieve relevant tasks from the training data."""
        n_examples = self.rag_kwargs["n_examples"]
        example_tasks = []
        if self.rag_kwargs["criteria"] == "knn":
            # Retrieve nearest neighbors as querys for task examples.
            n_examples_from_knn = len(query_task.references_texts)
            n_examples = min(n_examples, n_examples_from_knn)
            for i in range(n_examples):
                query_vec = query_task.references_vecs[i]
                query_text = query_task.references_texts[i]
                query_time = query_task.references_times[i]
                indices, _ = self.sampler.sample(query_vec, time_split=query_time)
                ref_vecs = [self.low_dim_embeddings[j] for j in indices]
                ref_texts = [self.texts[j] for j in indices]
                ref_times = [self.times[j] for j in indices]
                example_tasks.append(
                    QRTask(
                        query_vec,
                        query_text,
                        query_time,
                        ref_vecs,
                        ref_texts,
                        ref_times,
                    )
                )
        else:
            raise ValueError(f"Invalid criteria: {self.rag_kwargs['criteria']}.")
        return example_tasks

    def decode(self, low_dim_embedding: np.ndarray) -> Tuple[str, Any]:
        raise NotImplementedError(
            "Prompting-based generator does not support decoding single embeddings."
        )

    def decode_all(self, low_dim_embeddings: np.ndarray) -> List[Tuple[str, Any]]:
        messages = []
        neighbors = []
        for query in tqdm.tqdm(low_dim_embeddings, desc="Generating messages"):
            indices, dists = self.sampler.sample(query, time_split=self.test_time)
            ref_vecs = [self.low_dim_embeddings[i] for i in indices]
            ref_texts = [self.texts[i] for i in indices]
            ref_times = [self.times[i] for i in indices]
            task = QRTask(query, None, None, ref_vecs, ref_texts, ref_times)
            messages.append(self.get_prompt(task))
            neighbors.append(ref_texts)
        preds = process_chat_requests(
            self.model_name,
            messages,
            parameters={
                "temperature": 0,
                "top_p": 0.95,
                "response_format": {"type": "json_object"},
            },
            **self.api_kwargs,
        )
        return list(zip(preds, messages, neighbors))
